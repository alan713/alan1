{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+xeR4iu3lEoXS08nNNZLU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alan713/alan1/blob/master/DL_hw2_1_1Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# This will open a file browser\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "faZXqq_u16F2",
        "outputId": "e6ab0509-fd2a-477b-ce0a-f6de0e3aa8fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5d81fa55-439f-4ad4-901b-2677e1ec3aaa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5d81fa55-439f-4ad4-901b-2677e1ec3aaa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tiny-imagenet-200.zip to tiny-imagenet-200.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n📦 Installing required libraries...\")\n",
        "!pip install -q torch torchvision pillow numpy\n",
        "print(\"✅ All libraries installed successfully!\")\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM4wkBDe5Bk4",
        "outputId": "faefc66f-5746-4e24-e23b-1e0716c4bb0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📦 Installing required libraries...\n",
            "✅ All libraries installed successfully!\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Path to your uploaded zip file (in Colab's local storage)\n",
        "ZIP_PATH = '/content/tiny-imagenet-200.zip'  # Default location for uploaded files\n",
        "EXTRACT_TO = '/content/'  # Extract to Colab's local storage\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"📦 UNZIPPING TINY IMAGENET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# First, let's find the zip file\n",
        "print(\"Searching for zip file...\")\n",
        "zip_files = [f for f in os.listdir('/content/') if f.endswith('.zip')]\n",
        "print(f\"Found {len(zip_files)} zip file(s): {zip_files}\")\n",
        "\n",
        "if zip_files:\n",
        "    # Use the first zip file found (or the one matching our name)\n",
        "    if 'tiny-imagenet-200.zip' in zip_files:\n",
        "        ZIP_PATH = '/content/tiny-imagenet-200.zip'\n",
        "    else:\n",
        "        ZIP_PATH = f'/content/{zip_files[0]}'\n",
        "        print(f\"⚠️ Using: {zip_files[0]}\")\n",
        "\n",
        "if os.path.exists(ZIP_PATH):\n",
        "    print(f\"✅ Found zip file: {ZIP_PATH}\")\n",
        "\n",
        "    # Get file size\n",
        "    file_size_mb = os.path.getsize(ZIP_PATH) / (1024 * 1024)\n",
        "    print(f\"📊 File size: {file_size_mb:.2f} MB\")\n",
        "\n",
        "    print(\"⏳ Unzipping... (this takes ~2-3 minutes)\")\n",
        "\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(EXTRACT_TO)\n",
        "\n",
        "    print(\"✅ Unzipping complete!\")\n",
        "\n",
        "    # Find the extracted folder\n",
        "    DATASET_PATH = '/content/tiny-imagenet-200'\n",
        "\n",
        "    if os.path.exists(DATASET_PATH):\n",
        "        print(f\"\\n📂 Dataset location: {DATASET_PATH}\")\n",
        "\n",
        "        # Explore structure\n",
        "        print(\"\\n📊 Dataset Structure:\")\n",
        "        for item in os.listdir(DATASET_PATH):\n",
        "            item_path = os.path.join(DATASET_PATH, item)\n",
        "            if os.path.isdir(item_path):\n",
        "                num_items = len(os.listdir(item_path))\n",
        "                print(f\"  📁 {item}/ ({num_items} items)\")\n",
        "            else:\n",
        "                print(f\"  📄 {item}\")\n",
        "\n",
        "        # Check train folder\n",
        "        train_path = os.path.join(DATASET_PATH, 'train')\n",
        "        if os.path.exists(train_path):\n",
        "            classes = [d for d in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, d))]\n",
        "            print(f\"\\n✅ Training set: {len(classes)} classes\")\n",
        "\n",
        "            # Sample a class to see structure\n",
        "            if classes:\n",
        "                sample_class = classes[0]\n",
        "                sample_path = os.path.join(train_path, sample_class, 'images')\n",
        "                if os.path.exists(sample_path):\n",
        "                    num_images = len([f for f in os.listdir(sample_path) if f.endswith('.JPEG')])\n",
        "                    print(f\"✅ Sample class '{sample_class}': {num_images} images\")\n",
        "    else:\n",
        "        print(f\"❌ Could not find extracted folder at: {DATASET_PATH}\")\n",
        "\n",
        "else:\n",
        "    print(f\"❌ ZIP file not found!\")\n",
        "    print(f\"\\nSearched at: {ZIP_PATH}\")\n",
        "    print(\"\\n💡 To upload the file:\")\n",
        "    print(\"1. Click the 📁 folder icon on the left sidebar\")\n",
        "    print(\"2. Click the ⬆️ upload button\")\n",
        "    print(\"3. Select your tiny-imagenet-200.zip file\")\n",
        "    print(\"4. Wait for upload to complete\")\n",
        "    print(\"5. Re-run this cell\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyE1aYCu5Lb8",
        "outputId": "8c25532c-3e6a-455d-f198-262a5baf8251"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "📦 UNZIPPING TINY IMAGENET\n",
            "======================================================================\n",
            "Searching for zip file...\n",
            "Found 1 zip file(s): ['tiny-imagenet-200.zip']\n",
            "✅ Found zip file: /content/tiny-imagenet-200.zip\n",
            "📊 File size: 236.61 MB\n",
            "⏳ Unzipping... (this takes ~2-3 minutes)\n",
            "✅ Unzipping complete!\n",
            "\n",
            "📂 Dataset location: /content/tiny-imagenet-200\n",
            "\n",
            "📊 Dataset Structure:\n",
            "  📁 train/ (200 items)\n",
            "  📄 words.txt\n",
            "  📁 test/ (1 items)\n",
            "  📄 wnids.txt\n",
            "  📁 val/ (2 items)\n",
            "\n",
            "✅ Training set: 200 classes\n",
            "✅ Sample class 'n04118538': 500 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import random\n",
        "from typing import Tuple, List, Dict\n",
        "import json\n",
        "\n",
        "class TinyImageNetSubsetCreator:\n",
        "    \"\"\"\n",
        "    Creates a custom subset of Tiny ImageNet with specified number of classes.\n",
        "    Prepares data according to AlexNet specifications.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 source_path: str,\n",
        "                 output_path: str,\n",
        "                 num_classes: int = 100,\n",
        "                 train_size: int = 30000,\n",
        "                 val_size: int = 10000,\n",
        "                 test_size: int = 10000):\n",
        "        \"\"\"\n",
        "        Initialize dataset creator for Tiny ImageNet.\n",
        "\n",
        "        Args:\n",
        "            source_path: Path to extracted tiny-imagenet-200 folder\n",
        "            output_path: Path where processed dataset will be saved\n",
        "            num_classes: Number of classes to include (default: 100)\n",
        "            train_size: Total training images (default: 30000)\n",
        "            val_size: Total validation images (default: 10000)\n",
        "            test_size: Total testing images (default: 10000)\n",
        "        \"\"\"\n",
        "        self.source_path = Path(source_path)\n",
        "        self.output_path = Path(output_path)\n",
        "        self.num_classes = num_classes\n",
        "        self.train_size = train_size\n",
        "        self.val_size = val_size\n",
        "        self.test_size = test_size\n",
        "\n",
        "        # Calculate per-class splits\n",
        "        self.train_per_class = train_size // num_classes  # 300\n",
        "        self.val_per_class = val_size // num_classes      # 100\n",
        "        self.test_per_class = test_size // num_classes    # 100\n",
        "\n",
        "        # Tiny ImageNet has 500 images per class in train\n",
        "        # We need 500 total per class (300 train + 100 val + 100 test)\n",
        "        self.images_per_class = self.train_per_class + self.val_per_class + self.test_per_class\n",
        "\n",
        "        # Create output directories\n",
        "        self.splits = ['train', 'val', 'test']\n",
        "        self._create_directories()\n",
        "\n",
        "    def _create_directories(self):\n",
        "        \"\"\"Create directory structure for train/val/test splits.\"\"\"\n",
        "        for split in self.splits:\n",
        "            split_path = self.output_path / split\n",
        "            split_path.mkdir(parents=True, exist_ok=True)\n",
        "            print(f\"Created directory: {split_path}\")\n",
        "\n",
        "    def select_classes(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        Randomly select specified number of classes from Tiny ImageNet.\n",
        "\n",
        "        Returns:\n",
        "            List of selected class directory names (WordNet IDs)\n",
        "        \"\"\"\n",
        "        # Get all class directories from train folder\n",
        "        train_path = self.source_path / 'train'\n",
        "        all_classes = [d.name for d in train_path.iterdir()\n",
        "                      if d.is_dir() and not d.name.startswith('.')]\n",
        "\n",
        "        # Randomly select num_classes\n",
        "        random.seed(42)  # For reproducibility\n",
        "        selected_classes = random.sample(all_classes, self.num_classes)\n",
        "\n",
        "        print(f\"Selected {self.num_classes} classes from {len(all_classes)} available classes\")\n",
        "        return selected_classes\n",
        "\n",
        "    def collect_images_per_class(self, class_name: str) -> List[Path]:\n",
        "        \"\"\"\n",
        "        Collect images for a given class from Tiny ImageNet.\n",
        "\n",
        "        Args:\n",
        "            class_name: Name of the class directory (WordNet ID)\n",
        "\n",
        "        Returns:\n",
        "            List of image file paths\n",
        "        \"\"\"\n",
        "        # In Tiny ImageNet, images are in train/class_name/images/\n",
        "        class_images_path = self.source_path / 'train' / class_name / 'images'\n",
        "\n",
        "        # Get all JPEG images\n",
        "        all_images = list(class_images_path.glob('*.JPEG'))\n",
        "\n",
        "        # Tiny ImageNet has 500 images per class\n",
        "        if len(all_images) < self.images_per_class:\n",
        "            print(f\"Warning: Class {class_name} has only {len(all_images)} images\")\n",
        "            return all_images\n",
        "\n",
        "        # Take exactly the number we need\n",
        "        selected_images = random.sample(all_images, self.images_per_class)\n",
        "        return selected_images\n",
        "\n",
        "    def split_and_copy_images(self, images: List[Path], class_idx: int, class_name: str):\n",
        "        \"\"\"\n",
        "        Split images into train/val/test sets and copy to output directories.\n",
        "\n",
        "        Args:\n",
        "            images: List of image paths for a class\n",
        "            class_idx: Integer index for the class (0-99)\n",
        "            class_name: Name of the class (WordNet ID)\n",
        "        \"\"\"\n",
        "        # Shuffle images for random split\n",
        "        random.shuffle(images)\n",
        "\n",
        "        # Split images according to specified sizes\n",
        "        train_images = images[:self.train_per_class]\n",
        "        val_images = images[self.train_per_class:self.train_per_class + self.val_per_class]\n",
        "        test_images = images[self.train_per_class + self.val_per_class:\n",
        "                            self.train_per_class + self.val_per_class + self.test_per_class]\n",
        "\n",
        "        # Create class subdirectories and copy images\n",
        "        splits_data = {\n",
        "            'train': train_images,\n",
        "            'val': val_images,\n",
        "            'test': test_images\n",
        "        }\n",
        "\n",
        "        for split, split_images in splits_data.items():\n",
        "            # Create class directory within split\n",
        "            class_dir = self.output_path / split / f\"class_{class_idx:03d}_{class_name}\"\n",
        "            class_dir.mkdir(exist_ok=True)\n",
        "\n",
        "            # Copy images to class directory\n",
        "            for img_path in split_images:\n",
        "                dest_path = class_dir / img_path.name\n",
        "                shutil.copy2(img_path, dest_path)\n",
        "\n",
        "        print(f\"Class {class_idx:3d} ({class_name}): \"\n",
        "              f\"Train={len(train_images)}, Val={len(val_images)}, Test={len(test_images)}\")\n",
        "\n",
        "    def create_dataset(self):\n",
        "        \"\"\"\n",
        "        Main method to create the complete dataset with all splits.\n",
        "        \"\"\"\n",
        "        print(\"=\" * 70)\n",
        "        print(\"Starting Tiny ImageNet Subset Creation\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Set random seed for reproducibility\n",
        "        random.seed(42)\n",
        "\n",
        "        # Select classes\n",
        "        selected_classes = self.select_classes()\n",
        "\n",
        "        # Process each class\n",
        "        for class_idx, class_name in enumerate(selected_classes):\n",
        "            print(f\"Processing class {class_idx + 1}/{self.num_classes}: \", end=\"\")\n",
        "\n",
        "            # Collect images for this class\n",
        "            images = self.collect_images_per_class(class_name)\n",
        "\n",
        "            # Split and copy images\n",
        "            self.split_and_copy_images(images, class_idx, class_name)\n",
        "\n",
        "        # Save class mapping\n",
        "        class_mapping = {i: name for i, name in enumerate(selected_classes)}\n",
        "        mapping_file = self.output_path / 'class_mapping.json'\n",
        "        with open(mapping_file, 'w') as f:\n",
        "            json.dump(class_mapping, f, indent=2)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"Dataset creation completed!\")\n",
        "        print(f\"Total images - Train: {self.train_size}, Val: {self.val_size}, Test: {self.test_size}\")\n",
        "        print(f\"Class mapping saved to: {mapping_file}\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "\n",
        "class AlexNetImageNetDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset class for loading ImageNet data prepared according to AlexNet specifications.\n",
        "\n",
        "    Data preprocessing as per AlexNet paper (Section 2):\n",
        "    - Images resized to 256x256 (rescale shorter side to 256, then crop)\n",
        "    - Random 224x224 crops for training (center crop for validation/test)\n",
        "    - Horizontal flips for data augmentation (training only)\n",
        "    - RGB channel normalization\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 root_dir: str,\n",
        "                 split: str = 'train',\n",
        "                 transform: transforms.Compose = None):\n",
        "        \"\"\"\n",
        "        Initialize the dataset.\n",
        "\n",
        "        Args:\n",
        "            root_dir: Root directory containing train/val/test folders\n",
        "            split: One of 'train', 'val', or 'test'\n",
        "            transform: Optional transform to be applied on images\n",
        "        \"\"\"\n",
        "        self.root_dir = Path(root_dir) / split\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load all image paths and labels\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self._load_dataset()\n",
        "\n",
        "        # Load class mapping\n",
        "        mapping_file = Path(root_dir) / 'class_mapping.json'\n",
        "        with open(mapping_file, 'r') as f:\n",
        "            self.class_mapping = json.load(f)\n",
        "\n",
        "    def _load_dataset(self):\n",
        "        \"\"\"Load all image paths and corresponding labels.\"\"\"\n",
        "        class_dirs = sorted([d for d in self.root_dir.iterdir() if d.is_dir()])\n",
        "\n",
        "        for class_idx, class_dir in enumerate(class_dirs):\n",
        "            # Tiny ImageNet uses .JPEG extension\n",
        "            image_files = list(class_dir.glob('*.JPEG')) + \\\n",
        "                         list(class_dir.glob('*.jpg')) + \\\n",
        "                         list(class_dir.glob('*.jpeg')) + \\\n",
        "                         list(class_dir.glob('*.png'))\n",
        "\n",
        "            for img_path in image_files:\n",
        "                self.image_paths.append(img_path)\n",
        "                self.labels.append(class_idx)\n",
        "\n",
        "        print(f\"Loaded {len(self.image_paths)} images for {self.split} split\")\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Return the total number of images.\"\"\"\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
        "        \"\"\"\n",
        "        Get an image and its label.\n",
        "\n",
        "        Args:\n",
        "            idx: Index of the image\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (image_tensor, label)\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def get_alexnet_transforms(split: str = 'train') -> transforms.Compose:\n",
        "    \"\"\"\n",
        "    Get data transforms according to AlexNet paper specifications (Section 2).\n",
        "\n",
        "    Training transforms:\n",
        "    - Resize to 256x256 (Tiny ImageNet is 64x64, so we upscale)\n",
        "    - Random 224x224 crop\n",
        "    - Random horizontal flip\n",
        "    - Convert to tensor\n",
        "    - Normalize using ImageNet mean and std\n",
        "\n",
        "    Validation/Test transforms:\n",
        "    - Resize to 256x256\n",
        "    - Center crop to 224x224\n",
        "    - Convert to tensor\n",
        "    - Normalize using ImageNet mean and std\n",
        "\n",
        "    Args:\n",
        "        split: One of 'train', 'val', or 'test'\n",
        "\n",
        "    Returns:\n",
        "        Composed transforms\n",
        "    \"\"\"\n",
        "    # ImageNet mean and std for normalization (RGB channels)\n",
        "    imagenet_mean = [0.485, 0.456, 0.406]\n",
        "    imagenet_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    if split == 'train':\n",
        "        # Training transforms with data augmentation\n",
        "        transform = transforms.Compose([\n",
        "            # Resize to 256x256 (upscale from 64x64)\n",
        "            transforms.Resize((256, 256)),\n",
        "            # Random crop to 224x224 (as per AlexNet paper)\n",
        "            transforms.RandomCrop(224),\n",
        "            # Random horizontal flip for data augmentation\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            # Convert PIL Image to Tensor\n",
        "            transforms.ToTensor(),\n",
        "            # Normalize using ImageNet statistics\n",
        "            transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
        "        ])\n",
        "    else:\n",
        "        # Validation/Test transforms without augmentation\n",
        "        transform = transforms.Compose([\n",
        "            # Resize to 256x256\n",
        "            transforms.Resize((256, 256)),\n",
        "            # Center crop to 224x224\n",
        "            transforms.CenterCrop(224),\n",
        "            # Convert PIL Image to Tensor\n",
        "            transforms.ToTensor(),\n",
        "            # Normalize using ImageNet statistics\n",
        "            transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
        "        ])\n",
        "\n",
        "    return transform\n",
        "\n",
        "\n",
        "def create_dataloaders(data_dir: str,\n",
        "                       batch_size: int = 128,\n",
        "                       num_workers: int = 2) -> Dict[str, DataLoader]:\n",
        "    \"\"\"\n",
        "    Create DataLoaders for train, validation, and test sets.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Root directory containing the prepared dataset\n",
        "        batch_size: Batch size for training (AlexNet used 128)\n",
        "        num_workers: Number of worker processes for data loading\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing DataLoaders for each split\n",
        "    \"\"\"\n",
        "    dataloaders = {}\n",
        "\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        # Get appropriate transforms\n",
        "        transform = get_alexnet_transforms(split)\n",
        "\n",
        "        # Create dataset\n",
        "        dataset = AlexNetImageNetDataset(\n",
        "            root_dir=data_dir,\n",
        "            split=split,\n",
        "            transform=transform\n",
        "        )\n",
        "\n",
        "        # Create dataloader\n",
        "        # Shuffle training data, don't shuffle val/test\n",
        "        shuffle = (split == 'train')\n",
        "\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=True  # Faster data transfer to GPU\n",
        "        )\n",
        "\n",
        "        dataloaders[split] = dataloader\n",
        "        print(f\"{split.capitalize()} DataLoader: \"\n",
        "              f\"{len(dataset)} images, {len(dataloader)} batches\")\n",
        "\n",
        "    return dataloaders\n",
        "\n",
        "print(\"✅ All classes and functions loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsszIMIp5UyZ",
        "outputId": "5bd56f93-f8da-4ca3-ea73-5520ec739e7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All classes and functions loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🚀 CREATING CUSTOM 100-CLASS SUBSET FROM TINY IMAGENET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Paths\n",
        "SOURCE_PATH = '/content/tiny-imagenet-200'  # Where the zip was extracted\n",
        "OUTPUT_PATH = '/content/tiny_imagenet_100'  # Save to Colab (faster processing)\n",
        "# Note: Data will be lost when Colab disconnects. To save permanently, use:\n",
        "# OUTPUT_PATH = '/content/drive/MyDrive/tiny_imagenet_100'  # Uncomment to save to Drive\n",
        "\n",
        "print(f\"\\n📂 Source: {SOURCE_PATH}\")\n",
        "print(f\"💾 Output: {OUTPUT_PATH}\")\n",
        "print(f\"\\n⚠️ NOTE: Output is in Colab's temporary storage\")\n",
        "print(\"Data will be deleted when session ends.\")\n",
        "print(\"To save permanently, mount Drive and update OUTPUT_PATH\")\n",
        "\n",
        "# Check if source exists\n",
        "if not os.path.exists(SOURCE_PATH):\n",
        "    print(\"\\n❌ ERROR: Tiny ImageNet not found!\")\n",
        "    print(\"Make sure you ran CELL 3 to unzip the dataset\")\n",
        "else:\n",
        "    print(\"\\n✅ Source dataset found!\")\n",
        "\n",
        "    # Create the subset\n",
        "    creator = TinyImageNetSubsetCreator(\n",
        "        source_path=SOURCE_PATH,\n",
        "        output_path=OUTPUT_PATH,\n",
        "        num_classes=100,        # Select 100 out of 200 classes\n",
        "        train_size=30000,       # 300 per class\n",
        "        val_size=10000,         # 100 per class\n",
        "        test_size=10000         # 100 per class\n",
        "    )\n",
        "\n",
        "    # Run dataset creation\n",
        "    creator.create_dataset()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"✅ DATASET CREATION COMPLETED!\")\n",
        "    print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFtmSawK5tJ0",
        "outputId": "454c3d63-9f03-4eab-e799-5b1b57355210"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🚀 CREATING CUSTOM 100-CLASS SUBSET FROM TINY IMAGENET\n",
            "======================================================================\n",
            "\n",
            "📂 Source: /content/tiny-imagenet-200\n",
            "💾 Output: /content/tiny_imagenet_100\n",
            "\n",
            "⚠️ NOTE: Output is in Colab's temporary storage\n",
            "Data will be deleted when session ends.\n",
            "To save permanently, mount Drive and update OUTPUT_PATH\n",
            "\n",
            "✅ Source dataset found!\n",
            "Created directory: /content/tiny_imagenet_100/train\n",
            "Created directory: /content/tiny_imagenet_100/val\n",
            "Created directory: /content/tiny_imagenet_100/test\n",
            "======================================================================\n",
            "Starting Tiny ImageNet Subset Creation\n",
            "======================================================================\n",
            "Selected 100 classes from 200 available classes\n",
            "Processing class 1/100: Class   0 (n03255030): Train=300, Val=100, Test=100\n",
            "Processing class 2/100: Class   1 (n01770393): Train=300, Val=100, Test=100\n",
            "Processing class 3/100: Class   2 (n02099601): Train=300, Val=100, Test=100\n",
            "Processing class 4/100: Class   3 (n01945685): Train=300, Val=100, Test=100\n",
            "Processing class 5/100: Class   4 (n01443537): Train=300, Val=100, Test=100\n",
            "Processing class 6/100: Class   5 (n02815834): Train=300, Val=100, Test=100\n",
            "Processing class 7/100: Class   6 (n03637318): Train=300, Val=100, Test=100\n",
            "Processing class 8/100: Class   7 (n04149813): Train=300, Val=100, Test=100\n",
            "Processing class 9/100: Class   8 (n03980874): Train=300, Val=100, Test=100\n",
            "Processing class 10/100: Class   9 (n04133789): Train=300, Val=100, Test=100\n",
            "Processing class 11/100: Class  10 (n01917289): Train=300, Val=100, Test=100\n",
            "Processing class 12/100: Class  11 (n04275548): Train=300, Val=100, Test=100\n",
            "Processing class 13/100: Class  12 (n01944390): Train=300, Val=100, Test=100\n",
            "Processing class 14/100: Class  13 (n02423022): Train=300, Val=100, Test=100\n",
            "Processing class 15/100: Class  14 (n02948072): Train=300, Val=100, Test=100\n",
            "Processing class 16/100: Class  15 (n07753592): Train=300, Val=100, Test=100\n",
            "Processing class 17/100: Class  16 (n01910747): Train=300, Val=100, Test=100\n",
            "Processing class 18/100: Class  17 (n03838899): Train=300, Val=100, Test=100\n",
            "Processing class 19/100: Class  18 (n02165456): Train=300, Val=100, Test=100\n",
            "Processing class 20/100: Class  19 (n07579787): Train=300, Val=100, Test=100\n",
            "Processing class 21/100: Class  20 (n09428293): Train=300, Val=100, Test=100\n",
            "Processing class 22/100: Class  21 (n09246464): Train=300, Val=100, Test=100\n",
            "Processing class 23/100: Class  22 (n02906734): Train=300, Val=100, Test=100\n",
            "Processing class 24/100: Class  23 (n03388043): Train=300, Val=100, Test=100\n",
            "Processing class 25/100: Class  24 (n04596742): Train=300, Val=100, Test=100\n",
            "Processing class 26/100: Class  25 (n03089624): Train=300, Val=100, Test=100\n",
            "Processing class 27/100: Class  26 (n03424325): Train=300, Val=100, Test=100\n",
            "Processing class 28/100: Class  27 (n03770439): Train=300, Val=100, Test=100\n",
            "Processing class 29/100: Class  28 (n01983481): Train=300, Val=100, Test=100\n",
            "Processing class 30/100: Class  29 (n03662601): Train=300, Val=100, Test=100\n",
            "Processing class 31/100: Class  30 (n02802426): Train=300, Val=100, Test=100\n",
            "Processing class 32/100: Class  31 (n04254777): Train=300, Val=100, Test=100\n",
            "Processing class 33/100: Class  32 (n03250847): Train=300, Val=100, Test=100\n",
            "Processing class 34/100: Class  33 (n04417672): Train=300, Val=100, Test=100\n",
            "Processing class 35/100: Class  34 (n02950826): Train=300, Val=100, Test=100\n",
            "Processing class 36/100: Class  35 (n02364673): Train=300, Val=100, Test=100\n",
            "Processing class 37/100: Class  36 (n03706229): Train=300, Val=100, Test=100\n",
            "Processing class 38/100: Class  37 (n03983396): Train=300, Val=100, Test=100\n",
            "Processing class 39/100: Class  38 (n02410509): Train=300, Val=100, Test=100\n",
            "Processing class 40/100: Class  39 (n02927161): Train=300, Val=100, Test=100\n",
            "Processing class 41/100: Class  40 (n02129165): Train=300, Val=100, Test=100\n",
            "Processing class 42/100: Class  41 (n02486410): Train=300, Val=100, Test=100\n",
            "Processing class 43/100: Class  42 (n02669723): Train=300, Val=100, Test=100\n",
            "Processing class 44/100: Class  43 (n03976657): Train=300, Val=100, Test=100\n",
            "Processing class 45/100: Class  44 (n04465501): Train=300, Val=100, Test=100\n",
            "Processing class 46/100: Class  45 (n06596364): Train=300, Val=100, Test=100\n",
            "Processing class 47/100: Class  46 (n02123394): Train=300, Val=100, Test=100\n",
            "Processing class 48/100: Class  47 (n01855672): Train=300, Val=100, Test=100\n",
            "Processing class 49/100: Class  48 (n03404251): Train=300, Val=100, Test=100\n",
            "Processing class 50/100: Class  49 (n02977058): Train=300, Val=100, Test=100\n",
            "Processing class 51/100: Class  50 (n02281406): Train=300, Val=100, Test=100\n",
            "Processing class 52/100: Class  51 (n04356056): Train=300, Val=100, Test=100\n",
            "Processing class 53/100: Class  52 (n03160309): Train=300, Val=100, Test=100\n",
            "Processing class 54/100: Class  53 (n07768694): Train=300, Val=100, Test=100\n",
            "Processing class 55/100: Class  54 (n01774384): Train=300, Val=100, Test=100\n",
            "Processing class 56/100: Class  55 (n02279972): Train=300, Val=100, Test=100\n",
            "Processing class 57/100: Class  56 (n03085013): Train=300, Val=100, Test=100\n",
            "Processing class 58/100: Class  57 (n03393912): Train=300, Val=100, Test=100\n",
            "Processing class 59/100: Class  58 (n04067472): Train=300, Val=100, Test=100\n",
            "Processing class 60/100: Class  59 (n04179913): Train=300, Val=100, Test=100\n",
            "Processing class 61/100: Class  60 (n03617480): Train=300, Val=100, Test=100\n",
            "Processing class 62/100: Class  61 (n03733131): Train=300, Val=100, Test=100\n",
            "Processing class 63/100: Class  62 (n01768244): Train=300, Val=100, Test=100\n",
            "Processing class 64/100: Class  63 (n04008634): Train=300, Val=100, Test=100\n",
            "Processing class 65/100: Class  64 (n02814860): Train=300, Val=100, Test=100\n",
            "Processing class 66/100: Class  65 (n04259630): Train=300, Val=100, Test=100\n",
            "Processing class 67/100: Class  66 (n04023962): Train=300, Val=100, Test=100\n",
            "Processing class 68/100: Class  67 (n02190166): Train=300, Val=100, Test=100\n",
            "Processing class 69/100: Class  68 (n01641577): Train=300, Val=100, Test=100\n",
            "Processing class 70/100: Class  69 (n07720875): Train=300, Val=100, Test=100\n",
            "Processing class 71/100: Class  70 (n07734744): Train=300, Val=100, Test=100\n",
            "Processing class 72/100: Class  71 (n01774750): Train=300, Val=100, Test=100\n",
            "Processing class 73/100: Class  72 (n02106662): Train=300, Val=100, Test=100\n",
            "Processing class 74/100: Class  73 (n02837789): Train=300, Val=100, Test=100\n",
            "Processing class 75/100: Class  74 (n03599486): Train=300, Val=100, Test=100\n",
            "Processing class 76/100: Class  75 (n04074963): Train=300, Val=100, Test=100\n",
            "Processing class 77/100: Class  76 (n01784675): Train=300, Val=100, Test=100\n",
            "Processing class 78/100: Class  77 (n02730930): Train=300, Val=100, Test=100\n",
            "Processing class 79/100: Class  78 (n01984695): Train=300, Val=100, Test=100\n",
            "Processing class 80/100: Class  79 (n02788148): Train=300, Val=100, Test=100\n",
            "Processing class 81/100: Class  80 (n04371430): Train=300, Val=100, Test=100\n",
            "Processing class 82/100: Class  81 (n02074367): Train=300, Val=100, Test=100\n",
            "Processing class 83/100: Class  82 (n04597913): Train=300, Val=100, Test=100\n",
            "Processing class 84/100: Class  83 (n04398044): Train=300, Val=100, Test=100\n",
            "Processing class 85/100: Class  84 (n02808440): Train=300, Val=100, Test=100\n",
            "Processing class 86/100: Class  85 (n03763968): Train=300, Val=100, Test=100\n",
            "Processing class 87/100: Class  86 (n03902125): Train=300, Val=100, Test=100\n",
            "Processing class 88/100: Class  87 (n01742172): Train=300, Val=100, Test=100\n",
            "Processing class 89/100: Class  88 (n03444034): Train=300, Val=100, Test=100\n",
            "Processing class 90/100: Class  89 (n01644900): Train=300, Val=100, Test=100\n",
            "Processing class 91/100: Class  90 (n03930313): Train=300, Val=100, Test=100\n",
            "Processing class 92/100: Class  91 (n01629819): Train=300, Val=100, Test=100\n",
            "Processing class 93/100: Class  92 (n03649909): Train=300, Val=100, Test=100\n",
            "Processing class 94/100: Class  93 (n02403003): Train=300, Val=100, Test=100\n",
            "Processing class 95/100: Class  94 (n02395406): Train=300, Val=100, Test=100\n",
            "Processing class 96/100: Class  95 (n04285008): Train=300, Val=100, Test=100\n",
            "Processing class 97/100: Class  96 (n09332890): Train=300, Val=100, Test=100\n",
            "Processing class 98/100: Class  97 (n02094433): Train=300, Val=100, Test=100\n",
            "Processing class 99/100: Class  98 (n02504458): Train=300, Val=100, Test=100\n",
            "Processing class 100/100: Class  99 (n04456115): Train=300, Val=100, Test=100\n",
            "\n",
            "======================================================================\n",
            "Dataset creation completed!\n",
            "Total images - Train: 30000, Val: 10000, Test: 10000\n",
            "Class mapping saved to: /content/tiny_imagenet_100/class_mapping.json\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "✅ DATASET CREATION COMPLETED!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"📊 CREATING DATALOADERS WITH ALEXNET PREPROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "OUTPUT_PATH = '/content/tiny_imagenet_100'  # Match the path from Cell 5\n",
        "# If you saved to Drive in Cell 5, use: '/content/drive/MyDrive/tiny_imagenet_100'\n",
        "\n",
        "# Check if dataset was created\n",
        "if os.path.exists(OUTPUT_PATH):\n",
        "    # Create DataLoaders\n",
        "    dataloaders = create_dataloaders(\n",
        "        data_dir=OUTPUT_PATH,\n",
        "        batch_size=128,  # AlexNet batch size\n",
        "        num_workers=2    # Colab works well with 2 workers\n",
        "    )\n",
        "\n",
        "    # Verify the data\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"🔍 VERIFYING LOADED DATA\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    for split_name, dataloader in dataloaders.items():\n",
        "        # Get one batch\n",
        "        images, labels = next(iter(dataloader))\n",
        "\n",
        "        print(f\"\\n{split_name.upper()} SET:\")\n",
        "        print(f\"  ✓ Batch shape: {images.shape}\")\n",
        "        print(f\"  ✓ Labels shape: {labels.shape}\")\n",
        "        print(f\"  ✓ Image range: [{images.min():.3f}, {images.max():.3f}]\")\n",
        "        print(f\"  ✓ Total batches: {len(dataloader)}\")\n",
        "        print(f\"  ✓ Total images: {len(dataloader.dataset)}\")\n",
        "        print(f\"  ✓ Classes in batch: {len(torch.unique(labels))}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"✅ ALL DONE! Dataset ready for AlexNet training!\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Display summary\n",
        "    print(\"\\n📋 FINAL SUMMARY:\")\n",
        "    print(f\"  • Dataset: Tiny ImageNet (100 classes)\")\n",
        "    print(f\"  • Location: {OUTPUT_PATH}\")\n",
        "    print(f\"  • Training: 30,000 images (300/class)\")\n",
        "    print(f\"  • Validation: 10,000 images (100/class)\")\n",
        "    print(f\"  • Testing: 10,000 images (100/class)\")\n",
        "    print(f\"  • Image size: 224×224 (upscaled from 64×64)\")\n",
        "    print(f\"  • Preprocessing: AlexNet specifications\")\n",
        "    print(f\"  • Augmentation: Random crops + flips (train only)\")\n",
        "\n",
        "    # Show how to access in future sessions\n",
        "    print(\"\\n💡 TO USE IN FUTURE SESSIONS:\")\n",
        "    print(\"```python\")\n",
        "    print(\"dataloaders = create_dataloaders(\")\n",
        "    print(f\"    data_dir='{OUTPUT_PATH}',\")\n",
        "    print(\"    batch_size=128\")\n",
        "    print(\")\")\n",
        "    print(\"```\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\n❌ ERROR: Dataset not found at {OUTPUT_PATH}\")\n",
        "    print(\"Please run CELL 5 first!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8N1EgMQ55hn",
        "outputId": "dd3a46e8-010d-4c88-bc0d-e6badf72ceeb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "📊 CREATING DATALOADERS WITH ALEXNET PREPROCESSING\n",
            "======================================================================\n",
            "Loaded 30000 images for train split\n",
            "Train DataLoader: 30000 images, 235 batches\n",
            "Loaded 10000 images for val split\n",
            "Val DataLoader: 10000 images, 79 batches\n",
            "Loaded 10000 images for test split\n",
            "Test DataLoader: 10000 images, 79 batches\n",
            "\n",
            "======================================================================\n",
            "🔍 VERIFYING LOADED DATA\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRAIN SET:\n",
            "  ✓ Batch shape: torch.Size([128, 3, 224, 224])\n",
            "  ✓ Labels shape: torch.Size([128])\n",
            "  ✓ Image range: [-2.118, 2.640]\n",
            "  ✓ Total batches: 235\n",
            "  ✓ Total images: 30000\n",
            "  ✓ Classes in batch: 71\n",
            "\n",
            "VAL SET:\n",
            "  ✓ Batch shape: torch.Size([128, 3, 224, 224])\n",
            "  ✓ Labels shape: torch.Size([128])\n",
            "  ✓ Image range: [-2.118, 2.640]\n",
            "  ✓ Total batches: 79\n",
            "  ✓ Total images: 10000\n",
            "  ✓ Classes in batch: 2\n",
            "\n",
            "TEST SET:\n",
            "  ✓ Batch shape: torch.Size([128, 3, 224, 224])\n",
            "  ✓ Labels shape: torch.Size([128])\n",
            "  ✓ Image range: [-2.118, 2.640]\n",
            "  ✓ Total batches: 79\n",
            "  ✓ Total images: 10000\n",
            "  ✓ Classes in batch: 2\n",
            "\n",
            "======================================================================\n",
            "✅ ALL DONE! Dataset ready for AlexNet training!\n",
            "======================================================================\n",
            "\n",
            "📋 FINAL SUMMARY:\n",
            "  • Dataset: Tiny ImageNet (100 classes)\n",
            "  • Location: /content/tiny_imagenet_100\n",
            "  • Training: 30,000 images (300/class)\n",
            "  • Validation: 10,000 images (100/class)\n",
            "  • Testing: 10,000 images (100/class)\n",
            "  • Image size: 224×224 (upscaled from 64×64)\n",
            "  • Preprocessing: AlexNet specifications\n",
            "  • Augmentation: Random crops + flips (train only)\n",
            "\n",
            "💡 TO USE IN FUTURE SESSIONS:\n",
            "```python\n",
            "dataloaders = create_dataloaders(\n",
            "    data_dir='/content/tiny_imagenet_100',\n",
            "    batch_size=128\n",
            ")\n",
            "```\n"
          ]
        }
      ]
    }
  ]
}